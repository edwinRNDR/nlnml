{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bg5RkZdDZcI",
        "outputId": "a47aadfe-ea76-44d3-eb02-ddae56eeaf41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.58.1)\n",
            "Collecting pynndescent>=0.5 (from umap-learn)\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.66.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.41.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.2.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86831 sha256=28a3528374e01bb8d6b25a2e4854a1d7f97534aa48b2021e23ad29bc96d391ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/70/07/428d2b58660a1a3b431db59b806a10da736612ebbc66c1bcc5\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55615 sha256=5dcc347bba81b6b37627e92079ee1043fa2915bdef3de08c84bb154eb244f00f\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.10 umap-learn-0.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hET86czCDQiV"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "from os import path\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to GoogleDrive"
      ],
      "metadata": {
        "id": "-f8HobRcDnsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "vcTp8suNDqSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is where my dataset lives"
      ],
      "metadata": {
        "id": "1zL_65CEDsza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_location = '/content/gdrive/MyDrive/nln-dataset'"
      ],
      "metadata": {
        "id": "WtlxYkjFDu6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize features"
      ],
      "metadata": {
        "id": "yzXHQeAhD3Iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_location = f\"{dataset_location}/clip-features.csv\"\n",
        "dataset_location_normalized = f\"{dataset_location}/normalized\"\n",
        "\n",
        "if not path.exists(features_location):\n",
        "    print(\"Run NB01_extract_features first\")\n",
        "else:\n",
        "\n",
        "  df = pd.read_csv(features_location)\n",
        "\n",
        "  filter_labels = []\n",
        "\n",
        "  if len(filter_labels) > 0:\n",
        "      df = df[df[\"label\"].isin(filter_labels)]\n",
        "\n",
        "\n",
        "  features_df = df[df.columns[2:]]\n",
        "  id_class_df = df[df.columns[0:2]]\n",
        "\n",
        "  class_df = df[df.columns[1]]\n",
        "\n",
        "  labels = sorted(set([path.dirname(x) for x in df[\"id\"]]))\n",
        "\n",
        "\n",
        "  features = StandardScaler().fit_transform(features_df)\n",
        "\n",
        "  reducer = umap.UMAP()\n",
        "  embedding_with_classes = reducer.fit_transform(features, y=class_df)\n",
        "  embedding = reducer.fit_transform(features)\n",
        "\n",
        "\n",
        "  def get_image(path, zoom=1):\n",
        "      return OffsetImage(plt.imread(f\"{dataset_location_normalized}/{path}\"), zoom=zoom*0.1)\n",
        "\n",
        "\n",
        "  fig, ax = plt.subplots(1,1,figsize=(20,15))\n",
        "  plt.scatter(*embedding.T, s=0.1, c=class_df, cmap='Spectral', alpha=1.0)\n",
        "\n",
        "  x,y = embedding.T\n",
        "  for x0, y0, path in zip(x, y, df[\"id\"]):\n",
        "      ab = AnnotationBbox(get_image(path), (x0, y0), frameon=False)\n",
        "      ax.add_artist(ab)\n",
        "\n",
        "  embedding_df = pd.DataFrame( { \"x\": x, \"y\": y } )\n",
        "  embedding_df = pd.concat([id_class_df, embedding_df], axis=1)\n",
        "\n",
        "  embedding_df.to_csv(f\"{dataset_location}/clip-embedding_{'_'.join(str(x) for x in filter_labels)}.csv\", index=False)\n",
        "\n",
        "  cbar = plt.colorbar(boundaries=np.arange(len(labels)+1)-0.5)\n",
        "  cbar.set_ticks(np.arange(len(labels)))\n",
        "  cbar.set_ticklabels(labels)\n",
        "  plt.title(\"embedding\")\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvZ3IvlmD6rp",
        "outputId": "5dd2f2d5-4d59-439b-f98e-544d54ba725d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run NB01_extract_features first\n"
          ]
        }
      ]
    }
  ]
}