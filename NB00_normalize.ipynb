{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "from os import path\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import os"
      ],
      "metadata": {
        "id": "QumGzOQjBWph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Google Drive\n",
        "\n",
        "We want this because we will want to persist generated models in Google Drive. Otherwise we will lose our data as soon as we disconnect from Google Drive\n"
      ],
      "metadata": {
        "id": "yfvwaDYLBw9l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN0fA_pUBbNN",
        "outputId": "b867b5c4-4b24-43f4-95cf-4a05abad7fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is where my dataset lives\n"
      ],
      "metadata": {
        "id": "f4EKbylMCQVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_location = '/content/gdrive/MyDrive/nln-dataset'"
      ],
      "metadata": {
        "id": "AV2R_w38CZkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's double check that.\n",
        "\n",
        "In the next step we will list the class folders that reside in `dataset_location`"
      ],
      "metadata": {
        "id": "GNhsKAXTCq_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "for class_folder in glob(f\"{dataset_location}/original/*\"):\n",
        "  print(class_folder)"
      ],
      "metadata": {
        "id": "uVJ4AEpBC8fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalize images\n"
      ],
      "metadata": {
        "id": "z4vojfRuBIJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_width = 256"
      ],
      "metadata": {
        "id": "cx6HPPsMBOeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_location_original = f\"{dataset_location}/original\"\n",
        "\n",
        "# check if dataset is well-formed\n",
        "if not path.exists(dataset_location_original):\n",
        "    print(\"the dataset structure is not correct\")\n",
        "\n",
        "for label in sorted(glob(f\"{dataset_location_original}/*\")):\n",
        "    print(f\"'{path.basename(label)}': {len(glob(f'{label}/*'))}\")\n",
        "\n",
        "dataset_location_normalized = f\"{dataset_location}/normalized\"\n",
        "os.makedirs(dataset_location_normalized, exist_ok=True)\n",
        "\n",
        "to_process = [sorted(glob(f'{label}/*')) for label in sorted(glob(f\"{dataset_location_original}/*\"))]\n",
        "to_process_flat = [item for lst in to_process for item in lst]\n",
        "\n",
        "for file in tqdm(to_process_flat):\n",
        "    rp = path.relpath(file, dataset_location_original)\n",
        "    label = path.dirname(rp)\n",
        "    rp = path.splitext(rp)[0]\n",
        "\n",
        "    image = Image.open(file)\n",
        "\n",
        "    target_label = f\"{dataset_location_normalized}/{label}\"\n",
        "    if not path.exists(target_label):\n",
        "        os.makedirs(target_label)\n",
        "\n",
        "    target = f\"{dataset_location_normalized}/{rp}.png\"\n",
        "\n",
        "    if image.size[0] > image.size[1]:\n",
        "        resized_image = image.resize((max_width, int(image.size[1] * (max_width / image.size[0]))))\n",
        "    else:\n",
        "        resized_image = image.resize((int(image.size[0] * (max_width / image.size[1])), max_width))\n",
        "\n",
        "    resized_image.save(target)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jOlpG2_Bkt6",
        "outputId": "093e37d7-4545-43a4-e3aa-9165039f1b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the dataset structure is not correct\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        }
      ]
    }
  ]
}