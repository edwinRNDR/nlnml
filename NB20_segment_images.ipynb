{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
{
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/edwinRNDR/nlnml/blob/master/NB20_segment_images.ipynb)\n",
        "\n",
        "\n",
        "# CLIP prompt feature extractor"
      ],
      "metadata": {
        "id": "1H8cp3ZBNQ9G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0c4dpPyFug8",
        "outputId": "f36c6f81-b800-4b1e-8757-821782729b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-p74u6xke\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-p74u6xke\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: segment-anything\n",
            "  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36588 sha256=9bde7a2ddd26030eba505dbab7fb89619dc7db078bdd451f0c739532e9b86b79\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-35enswc5/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n",
            "Successfully built segment-anything\n",
            "Installing collected packages: segment-anything\n",
            "Successfully installed segment-anything-1.0\n",
            "--2023-11-20 18:56:44--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.173.166.48, 18.173.166.31, 18.173.166.74, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.173.166.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2564550879 (2.4G) [binary/octet-stream]\n",
            "Saving to: ‘sam_vit_h_4b8939.pth’\n",
            "\n",
            "sam_vit_h_4b8939.pt 100%[===================>]   2.39G   178MB/s    in 17s     \n",
            "\n",
            "2023-11-20 18:57:02 (140 MB/s) - ‘sam_vit_h_4b8939.pth’ saved [2564550879/2564550879]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from os import path\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "0ihGLBGEGjay"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to GoogleDrive"
      ],
      "metadata": {
        "id": "Gi37D4tIGIN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "LvPgWyVoGLN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is where my dataset lives\n"
      ],
      "metadata": {
        "id": "Q4YyFG8TGPwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_location = '/content/gdrive/MyDrive/nln-dataset'"
      ],
      "metadata": {
        "id": "OB3jBa1wGScX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segment images\n",
        "\n",
        "This can take several hours"
      ],
      "metadata": {
        "id": "iM3IABnJG2Dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_location_normalized = f\"{dataset_location}/normalized\"\n",
        "dataset_location_masked = f\"{dataset_location}/masked\"\n",
        "\n",
        "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "device = \"cuda\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "mask_generator = SamAutomaticMaskGenerator(sam, points_per_batch=16,  min_mask_region_area=500)\n",
        "\n",
        "os.makedirs(dataset_location_masked, exist_ok=True)\n",
        "\n",
        "to_process = [sorted(glob(f'{label}/*')) for label in sorted(glob(f\"{dataset_location_normalized}/*\"))]\n",
        "to_process_flat = [item for lst in to_process for item in lst]\n",
        "\n",
        "def make_mask_image(image, anns, image_file):\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
        "    sorted_anns = [x for x in sorted_anns if x['area'] > 500]\n",
        "\n",
        "    rp = path.relpath(image_file, dataset_location_normalized)\n",
        "    label = path.dirname(rp)\n",
        "\n",
        "    target_label = f\"{dataset_location_masked}/{label}\"\n",
        "    os.makedirs(target_label, exist_ok=True)\n",
        "\n",
        "    for (index, ann) in enumerate(sorted_anns):\n",
        "        img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
        "        img[:, :, 3] = 0\n",
        "        m = ann['segmentation']\n",
        "        color_mask = [ 1.0, 1.0, 1.0, 1.0]\n",
        "        img[m] = color_mask\n",
        "\n",
        "        img = img * image\n",
        "\n",
        "        bytes = np.uint8(img)\n",
        "        target = f\"{target_label}/{path.splitext(path.basename(image_file))[0]}-{index:03d}.png\"\n",
        "        Image.fromarray(bytes).save(target)\n",
        "\n",
        "for image_file in tqdm(to_process_flat):\n",
        "\n",
        "    rp = path.relpath(image_file, dataset_location_normalized)\n",
        "    label = path.dirname(rp)\n",
        "\n",
        "    target_label = f\"{dataset_location_masked}/{label}\"\n",
        "    target = f\"{target_label}/{path.splitext(path.basename(image_file))[0]}-000.png\"\n",
        "\n",
        "    if not path.exists(target):\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        image = cv2.imread(image_file)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        masks = mask_generator.generate(image)\n",
        "        make_mask_image(cv2.cvtColor(image, cv2.COLOR_RGB2RGBA), masks, image_file)"
      ],
      "metadata": {
        "id": "isijxcCiHCxp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
